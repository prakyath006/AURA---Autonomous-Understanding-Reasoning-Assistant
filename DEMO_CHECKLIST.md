# âœ… Hackathon Demo Checklist - Gemini API Proof

## ðŸŽ¯ How to Prove AURA Uses Gemini API to Judges

### Method 1: Live Network Inspection (BEST PROOF) â­
1. Open AURA in browser: `http://localhost:3000`
2. Open DevTools (F12)
3. Go to **Network** tab
4. Click "Preserve log"
5. **Capture an image** in AURA
6. **Point to the network request**:
   - URL: `generativelanguage.googleapis.com`
   - Endpoint: `/v1beta/models/gemini-2.5-flash:generateContent`
   - Method: POST
   - Status: 200 OK
7. **Show the request payload** (contains the image)
8. **Show the response** (Gemini's AI-generated text)

âœ… **This proves live API calls to Gemini at runtime**

---

### Method 2: Console Logs (EASY PROOF) â­
1. Open AURA in browser
2. Open DevTools Console (F12)
3. **Capture an image**
4. **Point to the logs**:
   ```
   ðŸ”‘ API Key loaded: [REDACTED]
   ðŸš€ Starting analysis with: {mode: 'reason', activeLens: 'universal'}
   ðŸ”„ Attempting connection to model: gemini-2.5-flash (Attempt 1/2)
   âœ… Success with model: gemini-2.5-flash
   âœ… Received response: {...}
   ```

âœ… **This shows real-time Gemini API interaction**

---

### Method 3: Code Walkthrough (TECHNICAL PROOF) â­
1. Open `src/lib/gemini.ts`
2. **Point to line 1**: Import official Google SDK
   ```typescript
   import { GoogleGenerativeAI } from "@google/generative-ai";
   ```
3. **Point to line 19-20**: Initialize Gemini
   ```typescript
   const apiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY as string;
   const genAI = new GoogleGenerativeAI(apiKey);
   ```
4. **Point to line 121-127**: Live API call
   ```typescript
   const model = genAI.getGenerativeModel({ model: modelName });
   const result = await model.generateContent([...]);
   const response = await result.response;
   const text = response.text();
   ```
5. Open `package.json`
6. **Point to line 12**: Official SDK dependency
   ```json
   "@google/generative-ai": "^0.24.1"
   ```

âœ… **This proves code uses official Gemini SDK**

---

### Method 4: Break the API (ULTIMATE PROOF) â­â­â­
1. Open `.env.local`
2. **Change API key** to something invalid: `INVALID_KEY`
3. **Try to capture** an image
4. **Show the error**: "Missing Gemini API Key" or API error
5. **Restore the real API key**
6. **Capture again** - it works!

âœ… **This proves the app DEPENDS on Gemini API**

---

## ðŸ“‹ Quick Facts to Tell Judges

1. **SDK**: Using official `@google/generative-ai` package (v0.24.1)
2. **Model**: Gemini 2.5 Flash (latest generation)
3. **API Calls**: 1 live call per scan (no caching)
4. **Multimodal**: Sends images + text to Gemini
5. **Endpoint**: `generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent`
6. **No Alternatives**: 100% Gemini - no other AI services

---

## ðŸŽ¬ Demo Script

**Say this to judges**:

> "AURA is powered entirely by Google Gemini 2.5 Flash API. Let me show you proof:
> 
> 1. [Open Network tab] Here's the browser's network inspector
> 2. [Capture image] I'll capture an image now
> 3. [Point to request] See this POST request to generativelanguage.googleapis.com? That's the live Gemini API call
> 4. [Show response] And here's Gemini's AI-generated response
> 5. [Open Console] The console logs also show the model name: gemini-2.5-flash
> 6. [Open code] In the code, we're using Google's official SDK
> 
> Every scan makes a real-time API call to Gemini - no caching, no alternative AI services."

---

## ðŸ“„ Documents to Reference

1. **GEMINI_API_VERIFICATION.md** - Comprehensive proof document
2. **README.md** - Project overview with API details
3. **src/lib/gemini.ts** - All Gemini API code (with header comment)
4. **package.json** - Shows official SDK dependency

---

## ðŸš¨ Common Judge Questions & Answers

**Q: "Are you using any other AI services?"**
A: "No, 100% Google Gemini API. You can verify in the Network tab - all AI requests go to generativelanguage.googleapis.com"

**Q: "Is this cached or pre-computed?"**
A: "No caching. Every scan makes a fresh API call. I can show you in the Network tab - each capture creates a new POST request."

**Q: "Which Gemini model are you using?"**
A: "Gemini 2.5 Flash as primary, with 2.0 Flash Exp and 1.5 Pro as fallbacks. You can see this in the console logs."

**Q: "Can you prove it's running at runtime?"**
A: "Yes! [Break the API key] If I invalidate the API key, the app fails. [Restore it] When I restore it, it works. This proves runtime dependency."

**Q: "Is this multimodal?"**
A: "Yes! We send images from the webcam along with text prompts to Gemini. You can see the base64 image data in the Network request payload."

---

## âœ… Final Checklist Before Demo

- [ ] `.env.local` has valid Gemini API key
- [ ] App is running (`npm run dev`)
- [ ] Browser DevTools ready (F12)
- [ ] Network tab open with "Preserve log" enabled
- [ ] Console tab visible
- [ ] Camera permissions granted
- [ ] `GEMINI_API_VERIFICATION.md` open for reference
- [ ] Know how to show code in `src/lib/gemini.ts`

---

## ðŸŽ¯ Key Proof Points

1. âœ… Network requests to `generativelanguage.googleapis.com`
2. âœ… Console logs showing `gemini-2.5-flash`
3. âœ… Official SDK in `package.json`
4. âœ… Code using `GoogleGenerativeAI` class
5. âœ… App breaks without valid API key

**You have multiple ways to prove Gemini API usage - you're fully compliant!** ðŸŽ‰
